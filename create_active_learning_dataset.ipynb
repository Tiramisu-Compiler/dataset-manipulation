{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61939a28-2b82-45ba-91d5-2295b13f5a18",
   "metadata": {},
   "source": [
    "### Specify the path to the dataset you want to modfiy and where to save it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad33b68f-e0e4-4c44-9c54-98e19e1b1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to run the helper function cells first\n",
    "# dataset_path = \"/data/mm12191/datasets/dataset_batch550000-838143.pkl\"\n",
    "dataset_path = \"/data/kb4083/datasets/cleaned_str/dataset_expr_batch550000-838143_train.pkl\"\n",
    "# path where the modified dataset should be saved and\n",
    "# the name of file without the extension\n",
    "save_path = \"/data/kb4083/datasets/active_learning/dataset_expr_batch550000-838143_train\"\n",
    "new_extension = \"pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91101da1-342d-469f-99ce-f569a8347bfe",
   "metadata": {},
   "source": [
    "### Read the current dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c415466c-5ef7-473f-986d-b14b7b0bb62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "# in case the dataset was stored in the json format\n",
    "if dataset_path.endswith(\"json\"):\n",
    "    # we open the dataset as a normal file\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        dataset_str = f.read()\n",
    "    programs_dict = json.loads(dataset_str)\n",
    "# in case the dataset was stored in the pkl format\n",
    "elif dataset_path.endswith(\"pkl\"):\n",
    "    # we un-pickle the file using the pickle library \n",
    "    with open(dataset_path, \"rb\") as f:\n",
    "        programs_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f546a8d-0a36-470d-b94b-68fa7a6d613c",
   "metadata": {},
   "source": [
    "### Apply modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f102d2-ed1c-445f-b0df-c40e5a2bc688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1367/131385 [2:18:57<280:53:36,  7.78s/it] "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "metrics = [\"abs_diff\", \"sq_diff\"]\n",
    "functions_list = list(programs_dict.keys())\n",
    "new_programs_dict = {}\n",
    "model = load_model_weights(\"/data/kb4083/cost_model/weights/best_model_release_code_model_555f.pt\")\n",
    "for index, function_name in enumerate(tqdm(functions_list)):\n",
    "    # Get the initial execution time for the program to calculate the speedups (initial exec time / transformed exec time)\n",
    "    program_exec_time = programs_dict[function_name][\n",
    "        \"initial_execution_time\"\n",
    "    ]\n",
    "    \n",
    "    new_programs_dict[function_name] = programs_dict[function_name].copy()\n",
    "    new_programs_dict[function_name][\"schedules_list\"] = [] \n",
    "    \n",
    "    # For each schedule (sequence of transformations) collected for this function\n",
    "    for schedule_index in range( len(programs_dict[function_name][\"schedules_list\"])):\n",
    "        # Get the schedule JSON representation\n",
    "        schedule_json = programs_dict[function_name][\"schedules_list\"][schedule_index].copy()\n",
    "        \n",
    "        # Get the transformed execution timeschedule_index\n",
    "        sched_exec_time = np.min(schedule_json[\"execution_times\"])\n",
    "        assert(sched_exec_time != 0)\n",
    "        \n",
    "        speed_up = program_exec_time / sched_exec_time\n",
    "        if schedule_index == 0: assert(speed_up==1)\n",
    "        programs_dict[function_name]\n",
    "        # Get the prediction of the mode\n",
    "        predicted_speedup = get_model_prediction(model, programs_dict[function_name], schedule_json)\n",
    "        \n",
    "        schedule_json[\"model_prediction\"] = predicted_speedup\n",
    "        # Calculate the error we want the active learning model to predict\n",
    "        if (\"abs_diff\" in metrics):\n",
    "            schedule_json[\"model_error_abs_diff\"] = abs(predicted_speedup - speed_up)\n",
    "        if (\"sq_diff\" in metrics):\n",
    "            schedule_json[\"model_error_sq_diff\"] = (predicted_speedup - speed_up)**2\n",
    "        # Save the new datapoint\n",
    "        new_programs_dict[function_name][\"schedules_list\"].append(schedule_json)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24199c1-bca4-4a6d-858b-8779a382b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbaa714-dc20-4bb2-b709-bf12922efd6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save the modified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8217ea-faab-4e63-8214-09ba5312458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = save_path +\".\"+new_extension\n",
    "if(new_extension == \"json\"):\n",
    "    with open(path, \"w\") as outfile:\n",
    "        json.dump(new_programs_dict, outfile)\n",
    "if(new_extension == \"pkl\"):\n",
    "    with open(path, 'wb') as handle:\n",
    "        pickle.dump(new_programs_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fed250-b1f5-4e15-9d10-7fdb56dda1f3",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a0d5b6-cada-4bae-b93b-838baddcc2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.path.insert(0, '/data/kb4083/tiramisu/tutorials/tutorial_autoscheduler/model/')\n",
    "from json_to_tensor import get_representation_template, get_schedule_representation, seperate_vector\n",
    "from hier_lstm import Model_Recursive_LSTM_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e118a4ad-47ea-416c-aa26-9cca572b1f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "def load_model_weights(model_weights_path):\n",
    "    # Get model information from the cost_model repo\n",
    "    with initialize(config_path=\"../cost_model/conf/\"):\n",
    "        config = compose(config_name='config.yaml')\n",
    "        \n",
    "        # Define the model\n",
    "        model = Model_Recursive_LSTM_v2(\n",
    "                input_size=config.model.input_size,\n",
    "                comp_embed_layer_sizes=list(config.model.comp_embed_layer_sizes),\n",
    "                drops=list(config.model.drops),\n",
    "                loops_tensor_size=8,\n",
    "            )\n",
    "        # Load the trained weights\n",
    "        device = torch.device('cpu')\n",
    "        model.load_state_dict(torch.load(model_weights_path, map_location=device))\n",
    "        model.eval()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ded22b46-f81d-42c2-8680-950f84eb5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of nested loops\n",
    "MAX_DEPTH = 5\n",
    "\n",
    "def get_model_prediction(model, program_dict,  sched_json):\n",
    "    program_json = program_dict[\"program_annotation\"]\n",
    "    no_sched_json = program_dict[\"schedules_list\"][0]\n",
    "    (\n",
    "        prog_tree,\n",
    "        comps_repr_templates_list,\n",
    "        loops_repr_templates_list,\n",
    "        comps_placeholders_indices_dict,\n",
    "        loops_placeholders_indices_dict,\n",
    "        comps_expr_tensor,\n",
    "        comps_expr_lengths,\n",
    "    ) = get_representation_template(program_json, no_sched_json, MAX_DEPTH)\n",
    "    comps_tensor, loops_tensor = get_schedule_representation(\n",
    "        program_json,\n",
    "        no_sched_json,\n",
    "        sched_json,\n",
    "        comps_repr_templates_list,\n",
    "        loops_repr_templates_list,\n",
    "        comps_placeholders_indices_dict,\n",
    "        loops_placeholders_indices_dict,\n",
    "        MAX_DEPTH,\n",
    "    )\n",
    "\n",
    "    x = comps_tensor\n",
    "    batch_size, num_comps, __dict__ = x.shape\n",
    "\n",
    "    x = x.view(batch_size * num_comps, -1)\n",
    "\n",
    "    (first_part, vectors, third_part) = seperate_vector(\n",
    "            x, num_transformations=4, pad=False\n",
    "        )\n",
    "\n",
    "    first_part = first_part.view(batch_size, num_comps, -1)\n",
    "\n",
    "    third_part = third_part.view(batch_size, num_comps, -1)\n",
    "\n",
    "    tree_tensor = (prog_tree, first_part, vectors, third_part, loops_tensor, comps_expr_tensor, comps_expr_lengths)\n",
    "\n",
    "    speedup = model.forward(tree_tensor)\n",
    "    return speedup.detach().numpy()[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99525572-3975-48ca-b632-4fa44e406945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e356365b-c4dd-406c-8635-6bee51929992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
