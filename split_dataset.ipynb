{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import shutil\n",
    "import json as json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_array(array_str):\n",
    "    array_str = array_str.group()    \n",
    "    array_str = array_str.replace('\\n','')\n",
    "    array_str = array_str.replace('\\t','')\n",
    "    array_str = array_str.replace('  ','')\n",
    "    array_str = array_str.replace(',',', ')\n",
    "    return array_str  \n",
    "\n",
    "def min_close_to_second_min(exec_list, base_exec, threshold=0.10):\n",
    "    sorted_exec_list = sorted(exec_list)\n",
    "    if (len(sorted_exec_list)<4):\n",
    "        return True\n",
    "    smallest = sorted_exec_list[0]\n",
    "    second_smallest = sorted_exec_list[1]\n",
    "    if smallest<0:\n",
    "        return False\n",
    "    sp1 = base_exec/smallest\n",
    "    sp2 = base_exec/second_smallest\n",
    "    if ((sp1-sp2)/sp1)>threshold:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = 'pkl'\n",
    "dataset_filename = '/data/kb4083/datasets/sample_20m_test.'+file_type\n",
    "val_dataset_filename = '/data/kb4083/datasets/sample_20m_test_even_smaller_val.'+file_type\n",
    "train_dataset_filename = '/data/kb4083/datasets/sample_20m_test_even_smaller_train.'+file_type\n",
    "\n",
    "if file_type == 'json':\n",
    "    with open(dataset_filename, 'r') as f:\n",
    "        dataset_str = f.read()\n",
    "    programs_dict=json.loads(dataset_str)\n",
    "elif file_type == 'pkl':\n",
    "    with open(dataset_filename, 'rb') as f:\n",
    "        programs_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.2\n",
    "func_names = list(programs_dict.keys())\n",
    "val_funcs = random.Random(42).sample(func_names, k=int(len(func_names)*split_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f79dbf374304b38b21ef0bf4d5e9f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1836 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367 1469\n",
      "number of functions with no schedules:  0\n"
     ]
    }
   ],
   "source": [
    "val_dict = dict()\n",
    "train_dict = dict()\n",
    "nb_anom = 0\n",
    "nb_norm = 0\n",
    "cpt = 0\n",
    "for func_name in tqdm(programs_dict):\n",
    "    if (len(programs_dict[func_name]['schedules_list'])<1): \n",
    "        cpt+=1\n",
    "        continue\n",
    "\n",
    "    base_exec = min(programs_dict[func_name]['schedules_list'][0]['execution_times'])\n",
    "    if func_name in val_funcs:\n",
    "        val_dict[func_name] = programs_dict[func_name]\n",
    "        val_dict[func_name]['schedules_list'] = [sched for sched in val_dict[func_name]['schedules_list'] if sched['execution_times']!=None and min_close_to_second_min(sched['execution_times'], base_exec)]\n",
    "        temp_sched_list = []\n",
    "        \n",
    "        for sched in val_dict[func_name]['schedules_list']:\n",
    "            if sched['execution_times']==None or (not min_close_to_second_min(sched['execution_times'], base_exec)): # if datapoint noisy\n",
    "                nb_anom+=1\n",
    "            else:\n",
    "                temp_sched_list.append(sched)\n",
    "        val_dict[func_name]['schedules_list'] = temp_sched_list       \n",
    "    else:\n",
    "        train_dict[func_name] = programs_dict[func_name]\n",
    "        \n",
    "        temp_sched_list = []\n",
    "        for sched in train_dict[func_name]['schedules_list']:\n",
    "            if sched['execution_times']==None or (not min_close_to_second_min(sched['execution_times'], base_exec)): # if datapoint noisy\n",
    "                nb_anom+=1\n",
    "            else:\n",
    "                temp_sched_list.append(sched)\n",
    "        train_dict[func_name]['schedules_list']= temp_sched_list\n",
    "        \n",
    "print(len(val_dict),len(train_dict))\n",
    "print(\"number of functions with no schedules: \", cpt)\n",
    "\n",
    "if file_type == 'json':\n",
    "    with open(val_dataset_filename, 'w') as f:\n",
    "        dataset_dumps = json.dumps(val_dict, indent = 4)\n",
    "        formated_dataset_json = re.sub(r'\\[[\\s*\\w*,\\\"]*\\]', format_array, dataset_dumps)\n",
    "        f.write(formated_dataset_json)   \n",
    "    with open(train_dataset_filename, 'w') as f:\n",
    "        dataset_dumps = json.dumps(train_dict, indent = 4)\n",
    "        formated_dataset_json = re.sub(r'\\[[\\s*\\w*,\\\"]*\\]', format_array, dataset_dumps)\n",
    "        f.write(formated_dataset_json)  \n",
    "        \n",
    "elif file_type == 'pkl':\n",
    "    with open(val_dataset_filename, 'wb') as f:\n",
    "        pickle.dump(val_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(train_dataset_filename, 'wb') as f:\n",
    "        pickle.dump(train_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(datasets_filenames, output_file): #merges multiple dataset json files into a single one\n",
    "    full_dataset_dict = dict()\n",
    "    for dataset_filename in datasets_filenames:\n",
    "        if dataset_filename.endswith('json'):\n",
    "            with open(dataset_filename, 'r') as f:\n",
    "                dataset_str = f.read()\n",
    "            programs_dict=json.loads(dataset_str)\n",
    "        elif dataset_filename.endswith('pkl'):\n",
    "            with open(dataset_filename, 'rb') as f:\n",
    "                programs_dict = pickle.load(f)\n",
    "        full_dataset_dict = {**full_dataset_dict, **programs_dict}\n",
    "    if output_file.endswith('json'):\n",
    "        with open(output_file, 'w') as f:\n",
    "            dataset_dumps = json.dumps(full_dataset_dict, indent = 4)\n",
    "            formated_dataset_json = re.sub(r'\\[[\\s*\\w*,\\\"]*\\]', format_array, dataset_dumps)\n",
    "            f.write(formated_dataset_json)\n",
    "    elif output_file.endswith('pkl'):\n",
    "        with open(output_file, 'wb') as f:\n",
    "            pickle.dump(full_dataset_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f'Created dataset file: {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset file: /data/kb4083/datasets/dataset_12mSingleCompFiltered_4mMatrices_2.6mMultiDataRaw.pkl\n"
     ]
    }
   ],
   "source": [
    "merge_datasets(['/data/mm12191/datasets/dataset_batch730000-759999.pkl',\n",
    "               '/data/mm12191/datasets/dataset_batch760000-780130.pkl',\n",
    "               '/data/kb4083/Filter_bad_programs/dataset_batch550000-716507_filtered_bad_programs.pkl'],\n",
    "              '/data/kb4083/datasets/dataset_12mSingleCompFiltered_4mMatrices_2.6mMultiDataRaw.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
